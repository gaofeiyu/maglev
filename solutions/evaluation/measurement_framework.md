# 量化评估与 ROI 框架 (Measurement & ROI Framework)

为了验证 Maglev 体系是否真正优于传统模式，我们需要一套残酷且诚实的量化评估标准。
本框架的核心假定是：**如果变革不能带来指数级 (2x-3x) 的效率提升，那么变革就是失败的。**

## 1. 变革门槛 (The Transformation Threshold)

我们并不追求微小的渐进式改进（如提升 20%）。鉴于组织转型的摩擦成本（心智迁移、流程重塑、工具学习），我们设定了以下硬性门槛：

- **及格线**: **200% (2x)** 提效。即 1 个 Maglev 小组的产出等于 2 个传统小组。
- **优秀线**: **300% (3x)** 提效。即 `1 Maglev Hour >= 3 Legacy Hours`。
- **熔断线**: 如果试点项目的提效低于 **50%**，应立即停止推广，重新检视模型。

---

## 2. 核心指标 (KPIs)

我们使用以下指标来衡量“提效”是否真实发生：

### 2.1 北极星指标：人力杠杆率 (Human Leverage)
$$
\text{Human Leverage} = \frac{\text{有效功能点 (Feature Points)}}{\text{人类投入工时 (Human Hours)}}
$$
- **定义**: 这里的“人力工时”指 VO+TP+XG 的总投入时间。
- **目标**: 传统模式下该比值通常为 X，Maglev 模式下应达到 3X。这直接反映了 AI 作为“外骨骼”带来的力量增幅。

### 2.2 辅助指标
- **TTM (Time to Market)**: 从 "Spec Confirm" 到 "Deployed to Prod" 的自然日天数。目标是 **天级交付** (vs 传统的周/月级)。
- **AI 贡献占比 (Code Contribution)**: AI 生成的代码行数 / 总代码行数。理想值应 > 80%。如果低于 50%，说明 TP 还在大量手写代码，转型不彻底。

---

## 3. 对比实验方法 (A/B Testing Protocol)

为了获得无可辩驳的数据，建议进行一次“赛马”。

### 3.1 影子项目 (Shadow Project)
- **选题**: 选取一个中等复杂度（约 3-5 天传统工时）、业务逻辑清晰的真实需求模块。
- **分组**:
    - **A 组 (Legacy Control)**: 1 PM + 1 Dev + 1 QA (标准配置)。使用 Jira, Word, 手写代码。
    - **B 组 (Maglev Pilot)**: 1 VO + 1 TP + 1 XG (新配置)。使用 One Repo, Markdown Spec, AI 生成。
- **规则**: 两组同时拿到原始需求，看谁先上线且 Bug 最少。

### 3.2 赛马结果判定
- **胜出**: B 组耗时 < A 组的 1/3，且 Bug 数持平或更少。 -> **推广**。
- **平局**: B 组耗时约为 A 组的 1/2。 -> **优化流程后再试**。
- **失败**: B 组耗时与 A 组接近，或 Bug 数显著增加。 -> **终止**。

---

## 4. 预期收益模型 (ROI Projection)

按照 3x 提效计算，假设一个 10 人研发团队的年成本为 500 万：
- **传统模式**: 产出 100 个单位价值。
- **Maglev 模式**:
    - **Option 1 (提速)**: 投入同样 500 万，产出 300 个单位价值。 (适合快速扩张期)
    - **Option 2 (降本)**: 投入 170 万 (3-4人)，产出 100 个单位价值。 (适合稳健经营期)

**成本项**:
- AI 工具订阅费 (Copilot/Cursor): 约 ¥2000/人/年。
- 转型阵痛期 (Training): 约 1 个月的产能下降。

**结论**: 哪怕算上工具费和培训成本，只要能维持 2x 以上的提效，投资回报期 (Payback Period)通常小于 3 个月。
